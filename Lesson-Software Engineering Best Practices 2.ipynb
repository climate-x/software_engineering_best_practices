{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineering Best Practices - Part 2\n",
    "\n",
    "In part 2 of software engineering practices, we'll learn about the following practices of software engineering and how they apply in data science.\n",
    "\n",
    "- Testing\n",
    "- Logging\n",
    "- Code reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "Testing the code is essential before deployment. It helps catch errors and faulty conclusions before they make any major impact. Today, employers are looking for data scientists with the skills to properly prepare their code for an industry setting, which includes testing their code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing And Data Science**\n",
    "- Problems that could occur in data science aren’t always easily detectable; we might have values being encoded incorrectly, features being used inappropriately, unexpected data breaking assumptions\n",
    "- To catch these errors, we have to check for the quality and accuracy of analysis in addition to the quality of code. Proper testing is necessary to avoid unexpected surprises and have confidence in your results.\n",
    "\n",
    "- **TEST DRIVEN DEVELOPMENT**: a development process where we write tests for tasks before even writing the code to implement those tasks.\n",
    "- **UNIT TEST**: a type of test that covers a “unit” of code, usually a single function, independently from the rest of the program.\n",
    "\n",
    "**Resources**\n",
    "- Four Ways Data Science Goes Wrong and How Test Driven Data Analysis Can Help: [Blog Post](https://www.predictiveanalyticsworld.com/machinelearningtimes/four-ways-data-science-goes-wrong-and-how-test-driven-data-analysis-can-help/6947/)\n",
    "- Ned Batchelder: Getting Started Testing: [Slide Deck](https://speakerdeck.com/pycon2014/getting-started-testing-by-ned-batchelder?slide=4) and [Presentation Video](https://www.youtube.com/watch?v=FxSsnHeWQBY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unit Tests**\n",
    "We want to test our functions in a way that is repeatable and automated. Ideally, we'd run a test program that runs all our unit tests and cleanly lets us know which ones failed and which ones succeeded. Fortunately, there are great tools available in Python that we can use to create effective unit tests!\n",
    "\n",
    "- Unit Test Advantages and Disadvantages\n",
    "The advantage of unit tests is that they are isolated from the rest of your program, and thus, no dependencies are involved. They don't require access to databases, APIs, or other external sources of information. However, passing unit tests isn’t always enough to prove that our program is working successfully. To show that all the parts of our program work with each other properly, communicating and transferring data between them correctly, we use integration tests. In this lesson, we'll focus on unit tests; however, when building larger programs, we will use integration tests as well.\n",
    "\n",
    "We can read about integration testing and how integration tests relate to unit tests [here](https://www.fullstackpython.com/integration-testing.html). That article contains other very useful links as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unit Testing Tools**\n",
    "To install pytest, run \n",
    "`pip install -U pytest` in terminal. You can see more information on getting started [here](https://docs.pytest.org/en/latest/getting-started.html).\n",
    "\n",
    "- Create a test file starting with `test_`\n",
    "- Define unit test functions that start with `test_` inside the test file\n",
    "- Enter `pytest` into terminal in the directory of test file and it will detect these tests for you!\n",
    "\n",
    "`test_` is the default - if you wish to change this, you can learn how to in this pytest [configuration](https://docs.pytest.org/en/latest/customize.html)\n",
    "\n",
    "In the test output, `period`s represent successful unit tests and `F's` represent failed unit tests. Since all you see is what test functions failed, it's wise to have only **one `assert` statement per test**. Otherwise, you wouldn't know exactly how many tests failed, and which tests failed.\n",
    "\n",
    "Tests won't be stopped by failed `assert` statements, but it will stop by syntax errors.\n",
    "\n",
    "More on `assert` keyword [here](https://www.w3schools.com/python/ref_keyword_assert.asp#:~:text=The%20assert%20keyword%20is%20used,False%2C%20check%20the%20example%20below.)\n",
    "\n",
    "[assert python reference](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement)\n",
    "\n",
    "The writing and reporting of [assertions in tests](https://docs.pytest.org/en/stable/assert.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original code: compute_launch_days.py\n",
    "```\n",
    "def days_until_launch(current_day, launch_day):\n",
    "    \"\"\"\"Returns the days left before launch.\n",
    "    \n",
    "    \"\"\"current_day (int) - current day in integer\n",
    "    '\"\"launch_day (int) - launch day in integer\n",
    "            return launch_day - current_day\n",
    "            \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test code: test_compute_launch_days.py\n",
    "```\n",
    "from compute_launch import days_until_launch\n",
    "\n",
    "def test_days_until_launch_4():\n",
    "    assert(days_until_launch(22, 26) == 4)\n",
    "\n",
    "def test_days_until_launch_0():\n",
    "    assert(days_until_launch(253, 253) == 0)\n",
    "\n",
    "def test_days_until_launch_0_negative():\n",
    "    assert(days_until_launch(83, 64) == 0)\n",
    "    \n",
    "def test_days_until_launch_1():\n",
    "    assert(days_until_launch(9, 10) == 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test 3 failed. Code amended as below:\n",
    "```\n",
    "def days_until_launch(current_day, launch_day):\n",
    "    \"\"\"\"Returns the days left before launch.\n",
    "    \n",
    "    current_day (int) - current day in integer\n",
    "    launch_day (int) - launch day in integer\n",
    "    \"\"\"\n",
    "    if current_day > launch_day:\n",
    "        return 0\n",
    "    else: \n",
    "        return launch_day - current_day\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def days_until_launch(current_day, launch_day):\n",
    "    \"\"\"\"Returns the days left before launch.\n",
    "    \n",
    "    current_day (int) - current day in integer\n",
    "    launch_day (int) - launch day in integer\n",
    "    \"\"\"\n",
    "    if current_day > launch_day:\n",
    "        return 0\n",
    "    else: \n",
    "        return launch_day - current_day\n",
    "days_until_launch(80, 52)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Driven Development and Data Science**\n",
    "- TEST DRIVEN DEVELOPMENT: writing tests before you write the code that’s being tested. Your test would fail at first, and you’ll know you’ve finished implementing a task when this test passes.\n",
    "Tests can check for all the different scenarios and edge cases you can think of, before even starting to write your function. This way, when you do start implementing your function, you can run this test to get immediate feedback on whether it works or not in all the ways you can think of, as you tweak your function.\n",
    "\n",
    "- When refactoring or adding to your code, tests help you rest assured that the rest of your code didn't break while you were making those changes. Tests also helps ensure that your function behavior is repeatable, regardless of external parameters, such as hardware and time.\n",
    "- Test driven development for data science is relatively new and has a lot of experimentation and breakthroughs appearing, which you can learn more about in the resources below.\n",
    "\n",
    "[Data Science TDD](https://www.linkedin.com/pulse/data-science-test-driven-development-sam-savage/)\n",
    "[TDD for Data Science](https://engineering.pivotal.io/post/test-driven-development-for-data-science/)\n",
    "[TDD is Essential for Good Data Science Here's Why](https://medium.com/uk-hydrographic-office/test-driven-development-is-essential-for-good-data-science-heres-why-db7975a03a44)\n",
    "[Testing Your Code](https://docs.python-guide.org/writing/tests/) (general python TDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "- Logging is valuable for understanding the events that occur while running program. For example, if you run your model over night and see that it's producing ridiculous results the next day, log messages can really help understand more about the context in which this occurred. \n",
    "\n",
    "**Log Messages**\n",
    "Logging is the process of recording messages to describe events that have occurred while running your software. Let's take a look at a few examples, and learn tips for writing good log messages.\n",
    "- Tip: Be professional and clear\n",
    "```\n",
    "Bad: Hmmm... this isn't working???\n",
    "Bad: idk.... :(\n",
    "Good: Couldn't parse file.\n",
    "```\n",
    "- Tip: Be concise and use normal capitalization\n",
    "```\n",
    "Bad: Start Product Recommendation Process\n",
    "Bad: We have completed the steps necessary and will now proceed with the recommendation process for the records in our product database.\n",
    "Good: Generating product recommendations.\n",
    "```\n",
    "\n",
    "- Tip: Choose the appropriate level for logging\n",
    "DEBUG - level you would use for anything that happens in the program.\n",
    "ERROR - level to record any error that occurs\n",
    "INFO - level to record all actions that are user-driven or system specific, such as regularly scheduled operations\n",
    "\n",
    "- Tip: Provide any useful information\n",
    "```\n",
    "Bad: Failed to read location data\n",
    "Good: Failed to read location data: store_id 8324971\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Reviews\n",
    "Code reviews benefit everyone in a team to promote best programming practices and prepare code for production. Let's go over what to look for in a code review and some tips on how to conduct one.\n",
    "\n",
    "[Code Review Lyst](https://github.com/lyst/MakingLyst/tree/master/code-reviews) \n",
    "[Code Review Best Practices](https://www.kevinlondon.com/2015/05/05/code-review-best-practices.html)\n",
    "\n",
    "**Questions to Ask Yourself When Conducting a Code Review**\n",
    "\n",
    "Is the code clean and modular?\n",
    "- Can I understand the code easily?\n",
    "- Does it use meaningful names and whitespace?\n",
    "- Is there duplicated code?\n",
    "- Can you provide another layer of abstraction?\n",
    "- Is each function and module necessary?\n",
    "- Is each function or module too long?\n",
    "\n",
    "Is the code efficient?\n",
    "- Are there loops or other steps we can vectorize?\n",
    "- Can we use better data structures to optimize any steps?\n",
    "- Can we shorten the number of calculations needed for any steps?\n",
    "- Can we use generators or multiprocessing to optimize any steps?\n",
    "\n",
    "Is documentation effective?\n",
    "- Are in-line comments concise and meaningful?\n",
    "- Is there complex code that's missing documentation?\n",
    "- Do function use effective docstrings?\n",
    "- Is the necessary project documentation provided?\n",
    "\n",
    "Is the code well tested?\n",
    "- Does the code high test coverage?\n",
    "- Do tests check for interesting cases?\n",
    "- Are the tests readable?\n",
    "- Can the tests be made more efficient?\n",
    "\n",
    "Is the logging effective?\n",
    "- Are log messages clear, concise, and professional?\n",
    "- Do they include all relevant and useful information?\n",
    "- Do they use the appropriate logging level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips for Conducting a Code Review**\n",
    "\n",
    "- When your coworker finishes up some code that they want to merge to the team's code base, they might send it to you for review. You provide feedback and suggestions, and then they may make changes and send it back to you. When you are happy with the code, you approve and it gets merged to the team's code base.\n",
    "\n",
    "- As you may have noticed, with code reviews you are now dealing with people, not just computers. So it's important to be thoughtful of their ideas and efforts. You are in a team and there will be differences in preferences. The goal of code review isn't to make all code follow your personal preferences, but a standard of quality for the whole team.\n",
    "\n",
    "- Tip: Use a code linter\n",
    "This isn't really a tip for code review, but can save you lots of time from code review! Using a Python code linter like [pylint](https://www.pylint.org/) can automatically check for coding standards and PEP 8 guidelines for you! It's also a good idea to agree on a style guide as a team to handle disagreements on code style, whether that's an existing style guide or one you create together incrementally as a team.\n",
    "\n",
    "- Tip: Explain issues and make suggestions\n",
    "Rather than commanding people to change their code a specific way because it's better, it will go a long way to explain to them the consequences of the current code and suggest changes to improve it. They will be much more receptive to your feedback if they understand your thought process and are accepting recommendations, rather than following commands. They also may have done it a certain way intentionally, and framing it as a suggestion promotes a constructive discussion, rather than opposition.\n",
    "```\n",
    "BAD: Make model evaluation code its own module - too repetitive.\n",
    "\n",
    "BETTER: Make the model evaluation code its own module. This will simplify models.py to be less repetitive and focus primarily on building models.\n",
    "\n",
    "GOOD: How about we consider making the model evaluation code its own module? This would simplify models.py to only include code for building models. Organizing these evaluations methods into separate functions would also allow us to reuse them with different models without repeating code.\n",
    "```\n",
    "\n",
    "- Tip: Keep your comments objective\n",
    "Try to avoid using the words \"I\" and \"you\" in your comments. You want to avoid comments that sound personal to bring the attention of the review to the code and not to themselves.\n",
    "```\n",
    "BAD: I wouldn't groupby genre twice like you did here... Just compute it once and use that for your aggregations.\n",
    "\n",
    "BAD: You create this groupby dataframe twice here. Just compute it once, save it as groupby_genre and then use that to get your average prices and views.\n",
    "\n",
    "GOOD: Can we group by genre at the beginning of the function and then save that as a groupby object? We could then reference that object to get the average prices and views without computing groupby twice.\n",
    "```\n",
    "\n",
    "- Tip: Provide code examples\n",
    "When providing a code review, you can save the author time and make it easy for them to act on your feedback by writing out your code suggestions. This shows you are willing to spend some extra time to review their code and help them out. It can also just be much quicker for you to demonstrate concepts through code rather than explanations.\n",
    "\n",
    "Let's say you were reviewing code that included the following lines:\n",
    "\n",
    "```\n",
    "first_names = []\n",
    "last_names = []\n",
    "\n",
    "for name in enumerate(df.name):\n",
    "    first, last = name.split(' ')\n",
    "    first_names.append(first)\n",
    "    last_names.append(last)\n",
    "\n",
    "df['first_name'] = first_names\n",
    "df['last_names'] = last_names\n",
    "```\n",
    "```\n",
    "BAD: You can do this all in one step by using the pandas str.split method.\n",
    "GOOD: We can actually simplify this step to the line below using the pandas str.split method. Found this on this stack overflow post: https://stackoverflow.com/questions/14745022/how-to-split-a-column-into-two-columns\n",
    "\n",
    "df['first_name'], df['last_name'] = df['name'].str.split(' ', 1).str\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pylint in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.4.4)\n",
      "Requirement already satisfied: mccabe<0.7,>=0.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pylint) (0.6.1)\n",
      "Requirement already satisfied: isort<5,>=4.2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pylint) (4.3.21)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pylint) (0.4.3)\n",
      "Requirement already satisfied: astroid<2.4,>=2.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pylint) (2.3.3)\n",
      "Requirement already satisfied: lazy-object-proxy==1.4.* in c:\\users\\pc\\anaconda3\\lib\\site-packages (from astroid<2.4,>=2.3.0->pylint) (1.4.3)\n",
      "Requirement already satisfied: six~=1.12 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from astroid<2.4,>=2.3.0->pylint) (1.14.0)\n",
      "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
      "  Downloading typed_ast-1.4.1-cp37-cp37m-win_amd64.whl (155 kB)\n",
      "Requirement already satisfied: wrapt==1.11.* in c:\\users\\pc\\anaconda3\\lib\\site-packages (from astroid<2.4,>=2.3.0->pylint) (1.11.2)\n",
      "Installing collected packages: typed-ast\n",
      "Successfully installed typed-ast-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pylint\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
